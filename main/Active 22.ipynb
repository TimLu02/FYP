{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8bf3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Library Calls\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import montage \n",
    "from skimage.transform import rotate\n",
    "from sklearn.model_selection import train_test_split as ttt\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from pylab import *\n",
    "import gc\n",
    "import torchmetrics \n",
    "import radiomics\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.image\n",
    "import SimpleITK as sitk\n",
    "import radiomics\n",
    "from radiomics import featureextractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d16a3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable definition\n",
    "IMAGE_PATH = 'data/MICCAI_BraTS_2019_Data_Training'\n",
    "CSV_FILE='data/MICCAI_BraTS_2019_Data_Training/new.csv'\n",
    "MODEL_PATH = 'log/22/'\n",
    "\n",
    "# number of slices, meaning how many slices we are taking from one image file  \n",
    "SLICE_NUM = 10\n",
    "# Original Image Size\n",
    "IMAGE_SIZE=240\n",
    "# Image size after cropping\n",
    "HEIGHT=128\n",
    "WIDTH=144\n",
    "\n",
    "# Batch size constant\n",
    "BATCH_SIZE= 1\n",
    "# input_channel corresponds to the number of different types of images used: \n",
    "# e.g: T1, T2, T1_flair, etc. \n",
    "# only using one type of images at the moment\n",
    "INPUT_CHANNEL=2\n",
    "EPOCH = 50\n",
    "LEARNING_RATE = 0.001\n",
    "SLICE_STARTS=torch.load('data/slice_starts.pt')\n",
    "WEIGHT = torch.load('data/weight.pt')\n",
    "device = torch.device('cuda')\n",
    "LOAD_CURRENT = True\n",
    "LOAD_BEST = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "596b5456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Data loader for easy data access. \n",
    "\n",
    "Output shape for get_item: X [slices, input_channels, W, H ]\n",
    "                           y [slices, W, H, ]\n",
    "Notes: the output channel for y has dimension of 1 and has value in range of (0,3).\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Simple helper function for retriving images given the path\n",
    "def get_image(image_path,image_cat,image_id,image_type):\n",
    "    t1_data=nib.load(os.path.join(image_path,image_cat,image_id,'')+image_id+'_t1.nii.gz').get_fdata()\n",
    "    t1ce_data=nib.load(os.path.join(image_path,image_cat,image_id,'')+image_id+'_t1ce.nii.gz').get_fdata()\n",
    "    t2_data=nib.load(os.path.join(image_path,image_cat,image_id,'')+image_id+'_t2.nii.gz').get_fdata()\n",
    "    seg_data=nib.load(image_path+'/'+image_cat+'/'+image_id+'/'+image_id+'_seg.nii.gz').get_fdata()\n",
    "    flair_data=nib.load(os.path.join(image_path,image_cat,image_id,'')+image_id+'_flair.nii.gz').get_fdata()\n",
    "    result={'t1':t1_data,'t1ce':t1ce_data,'t2':t2_data,'seg':seg_data,'flair':flair_data}\n",
    "   \n",
    "    return result[image_type]; \n",
    "\n",
    "\n",
    "class BraTS19Dataset(Dataset):\n",
    "    def __init__(self, csv_f,i_path,i_type):\n",
    "        self.source=pd.read_csv(csv_f)\n",
    "        self.image_path=i_path\n",
    "        self.type=i_type\n",
    "        self.batch=BATCH_SIZE\n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "     \n",
    "    def __getitem__(self,idx):\n",
    "        image_cat=self.source.iloc[idx,0]\n",
    "        image_id=self.source.iloc[idx,1]\n",
    "        starts=SLICE_STARTS[idx].int()\n",
    "        age=self.source.iloc[idx,2]\n",
    "        sur=self.source.iloc[idx,3]\n",
    "        stu=self.source.iloc[idx,4]\n",
    "        if sur<300: \n",
    "            cla = 0\n",
    "        elif sur<450:\n",
    "            cla=1\n",
    "        else:\n",
    "            cla =2\n",
    "        #classification class \n",
    "        \n",
    "        # get the image and its corresponding mask \n",
    "        img = np.zeros((INPUT_CHANNEL,IMAGE_SIZE,IMAGE_SIZE,155))\n",
    "        \n",
    "        for i in range(INPUT_CHANNEL):\n",
    "            img[i]=get_image(self.image_path,image_cat,image_id,self.type[i])\n",
    "        \n",
    "     \n",
    "        mask=get_image(self.image_path,image_cat,image_id,'seg')\n",
    "        \n",
    "        \n",
    "        # change label 4 to 3 for easy index handling\n",
    "        \n",
    "        mask[mask==4]=3\n",
    "        \n",
    "        # initialize results arrays\n",
    "        X=np.zeros((INPUT_CHANNEL,HEIGHT,WIDTH,SLICE_NUM))\n",
    "        y=np.zeros((HEIGHT,WIDTH,SLICE_NUM))\n",
    "        X = img[:,50:50+HEIGHT,55:55+WIDTH,starts-5:starts-5+SLICE_NUM]\n",
    "        y = mask[50:50+HEIGHT,55:55+WIDTH,starts-5:starts-5+SLICE_NUM]\n",
    "        X=torch.from_numpy(X)\n",
    "        y=torch.from_numpy(y)\n",
    "        \n",
    "        \n",
    "      \n",
    "       \n",
    "       \n",
    "        y = y.long()\n",
    "#        y = F.one_hot(y,num_classes=4)\n",
    "        return (X.permute(3,0,1,2),y.permute(2,0,1),(age,sur,stu,cla))\n",
    "    \n",
    "def GetBraTS19Dataset(csv,ipath,itype,batch_size=1,shuffle=True,pin_memory=True):\n",
    "    data = BraTS19Dataset(csv,ipath,itype)\n",
    "    leng = [int(0.6* len(data)),int(0.2* len(data)),len(data) - int(0.6 * len(data))-int(0.2 * len(data))]\n",
    "    train,eva,test=torch.utils.data.random_split(data,leng)\n",
    "    train=DataLoader(train,batch_size=batch_size,shuffle=shuffle,pin_memory=pin_memory)\n",
    "    eva=DataLoader(eva,batch_size=batch_size,shuffle=shuffle,pin_memory=pin_memory)\n",
    "    test=DataLoader(eva,batch_size=batch_size,shuffle=shuffle,pin_memory=pin_memory)\n",
    "    return train,eva,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b5f1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet model\n",
    "class Unet(nn.Module):\n",
    "\n",
    "    def encoder_block(self,in_channels,out_channels,k=3,conv2d_pad1=(1,1),conv2d_pad2=(1,1)):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=k,padding=conv2d_pad1),\n",
    "            nn.GroupNorm(32,out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size=k,padding=conv2d_pad2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(32,out_channels),\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    # actual output channel size = output_channel/2\n",
    "    def decoder_block(self,in_channels,out_channels,k=3,s=2,conv2d_pad1=(1,1),conv2d_pad2=(1,1),convtrans2d_pad=(0,0)):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=k,padding=conv2d_pad1),\n",
    "            nn.GroupNorm(32,out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size=k,padding=conv2d_pad2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(32,out_channels),\n",
    "            nn.ConvTranspose2d(out_channels,int(out_channels/2),kernel_size=2,stride=s,padding=convtrans2d_pad),\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def bottle_neck(self,in_channels,out_channels,k=3):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=k,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(32,out_channels),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size=k,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.GroupNorm(32,out_channels),\n",
    "            nn.ConvTranspose2d(out_channels,in_channels,kernel_size=2,stride=2,padding=(0,0),output_padding=(0,0)),\n",
    "        )\n",
    "        return block\n",
    "    \n",
    "        \n",
    "    def final_block(self,in_channels,out_channels,k):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,int(in_channels/2),kernel_size=k,padding=(1,1)),\n",
    "            nn.GroupNorm(16,int(in_channels/2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(int(in_channels/2),out_channels,kernel_size=k,padding=(1,1)),\n",
    "            nn.GroupNorm(4,out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size=1,stride=1),\n",
    "            nn.Softmax(dim=1),\n",
    "            \n",
    "        )\n",
    "        return block\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Unet, self).__init__()\n",
    "        self.en1=self.encoder_block(in_channel,32)\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.en2=self.encoder_block(32,64)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.en3=self.encoder_block(64,128)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.en4=self.encoder_block(128,256)\n",
    "        self.max4 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.bn=self.bottle_neck(256,512)\n",
    "        self.dc4=self.decoder_block(512,256)\n",
    "        self.dc3=self.decoder_block(256,128)\n",
    "        self.dc2=self.decoder_block(128,64)\n",
    "        self.final=self.final_block(64,out_channel,k=3)\n",
    "   \n",
    "    def forward(self,x):\n",
    "        encoder_block1=self.en1(x)\n",
    "        mp1 = self.max1(encoder_block1)\n",
    "        encoder_block2=self.en2(mp1)\n",
    "        mp2 = self.max2(encoder_block2)\n",
    "        encoder_block3=self.en3(mp2)\n",
    "        mp3 = self.max3(encoder_block3)\n",
    "        encoder_block4=self.en4(mp3)\n",
    "        mp4 = self.max4(encoder_block4)\n",
    "        bottleneck_block1 =self.bn(mp4)\n",
    "        \n",
    "        cat_block4= torch.cat((bottleneck_block1,encoder_block4),1)\n",
    "        decoder_block4=self.dc4(cat_block4)\n",
    "        \n",
    "        cat_block3= torch.cat((decoder_block4,encoder_block3),1)\n",
    "        decoder_block3=self.dc3(cat_block3)\n",
    "        \n",
    "        cat_block2= torch.cat((decoder_block3,encoder_block2),1)\n",
    "        decoder_block2=self.dc2(cat_block2)\n",
    "        \n",
    "        cat_block1= torch.cat((decoder_block2,encoder_block1),1)\n",
    "        \n",
    "        result=self.final(cat_block1)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a146913c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DiceScore(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiceScore, self).__init__()\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        dice = torchmetrics.Dice(average = 'micro').to(device)\n",
    "        macdice = torchmetrics.Dice(num_classes=4,average = 'micro').to(device)\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        y_pred1 = F.one_hot(torch.argmax(y_pred,dim=3),num_classes=4)\n",
    "      \n",
    "        yp0 = y_pred1[:,:,:,0].contiguous().view(-1)\n",
    "        yt0 = y_true[:,:,:,0].contiguous().view(-1)\n",
    "        t0 = dice(yp0,yt0)\n",
    "        \n",
    "        yp1 = y_pred1[:,:,:,1].contiguous().view(-1)\n",
    "        yt1 = y_true[:,:,:,1].contiguous().view(-1)\n",
    "        t1 = dice(yp1,yt1)\n",
    "        \n",
    "        yp2 = y_pred1[:,:,:,2].contiguous().view(-1)\n",
    "        yt2 = y_true[:,:,:,2].contiguous().view(-1)\n",
    "        t2 = dice(yp2,yt2)\n",
    "        \n",
    "    \n",
    "        yp3 = y_pred1[:,:,:,3].contiguous().view(-1)\n",
    "        yt3 = y_true[:,:,:,3].contiguous().view(-1)\n",
    "        t3 = dice(yp3,yt3)\n",
    "\n",
    "\n",
    "        return macdice(y_pred1,y_true),t0,t1,t2,t3\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0a10e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        total_loss=0.0\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        for i in range(4):\n",
    "            preds =torch.flatten(y_pred[:,:,:,i])\n",
    "         \n",
    "            target =torch.flatten(y_true[:,:,:,i])\n",
    "            intersection = torch.sum((preds * target))\n",
    "\n",
    "            dsc = (2. * intersection + 1) / (torch.sum(preds) + torch.sum(target) + 1)\n",
    "            total_loss+=(1-dsc)\n",
    "        \n",
    "        \n",
    "       \n",
    "        return total_loss/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d7f03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "def training(dataset, model, opt,  dev, batch_size, lr):\n",
    "    print('Training in session: ')\n",
    "    iou=torchmetrics.JaccardIndex('multiclass',num_classes=4,validate_args=False).to(device)\n",
    "    dic = DiceScore().to(device)\n",
    "    IoU=[]\n",
    "    md=[]\n",
    "    d0=[]\n",
    "    d1=[]\n",
    "    d2=[]\n",
    "    d3=[]\n",
    "    epoch_loss=0.0\n",
    "    dataset=tqdm(dataset)\n",
    "    for index, batch in enumerate(dataset):\n",
    "        \n",
    "        # reshape the data and load the data to gpu\n",
    "        x, y,other= batch \n",
    "        a,b,c,d,e=x.shape\n",
    "        x=x.reshape(a*b,c,d,e)\n",
    "        x=x.float()\n",
    "\n",
    "        a,b,c,d=y.shape\n",
    "        y=y.reshape(a*b,c,d)\n",
    "        \n",
    "        x,y=x.to(device),y.to(device)\n",
    "       \n",
    "        \n",
    "      \n",
    "        \n",
    "        \n",
    "        \n",
    "        loss_fn = DiceLoss().to(device)\n",
    "       \n",
    "        # training model\n",
    "        res = model(x)\n",
    "        res=res.to(device)\n",
    "        loss = loss_fn(res.permute(0,2,3,1).to(device),F.one_hot(y,num_classes=4).to(device)).to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), gc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Loss \n",
    "        print(\"Batch_id: \", index,\"Training loss: \", loss.item())\n",
    "        epoch_loss+=loss.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #IoU\n",
    "        bac = iou(torch.argmax(res,dim = 1).to(device),y.to(device)).to(device)\n",
    "        print(\"Batch_id: \", index,\"Training IoU: \", bac)\n",
    "        IoU.append(bac)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Dice Score\n",
    "        \n",
    "        t,t0,t1,t2,t3=dic(res.permute(0,2,3,1).to(device),F.one_hot(y,num_classes=4).to(device))\n",
    "        \n",
    "        \n",
    "            \n",
    "        print(\"Batch_id: \", index,\"Training Mean Dice Score: \", t)\n",
    "        md.append(t)\n",
    "            \n",
    "        print(\"Batch_id: \", index,\"Training Non-tumor Dice Score: \", t0)\n",
    "        d0.append(t0)\n",
    "            \n",
    "        print(\"Batch_id: \", index,\"Training NCR/NET Dice Score: \", t1)\n",
    "        d1.append(t1)\n",
    "            \n",
    "        print(\"Batch_id: \", index,\"Training ED Dice Score: \", t2)\n",
    "        d2.append(t2)\n",
    "            \n",
    "        print(\"Batch_id: \", index,\"Training ET Dice Score: \", t3)\n",
    "        d3.append(t3)\n",
    "\n",
    "        \n",
    "            \n",
    "    IoU=torch.tensor(IoU)\n",
    "    md = torch.tensor(md)\n",
    "    d0=torch.tensor(d0)\n",
    "    d1=torch.tensor(d1)\n",
    "    d2=torch.tensor(d2)\n",
    "    d3=torch.tensor(d3)\n",
    "    return torch.mean(IoU),epoch_loss,torch.mean(md),torch.mean(d0),torch.mean(d1),torch.mean(d2),torch.mean(d3)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "#        IoU.append(iou(res,y.float()).to(torch.device('cpu')))\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daed1ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluation(dataset, model):\n",
    "    print('Evaluation in session: ')\n",
    "    iou=torchmetrics.JaccardIndex('multiclass',num_classes=4,validate_args=False).to(device)\n",
    "    dic = DiceScore().to(device)\n",
    "    IoU=[]\n",
    "    md=[]\n",
    "    d0=[]\n",
    "    d1=[]\n",
    "    d2=[]\n",
    "    d3=[]\n",
    "    epoch_loss=0.0\n",
    "    dataset=tqdm(dataset)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for index, batch in enumerate(dataset):\n",
    "        \n",
    "            # reshape the data and load the data to gpu\n",
    "            x, y,other= batch \n",
    "            a,b,c,d,e=x.shape\n",
    "            x=x.reshape(a*b,c,d,e)\n",
    "            x=x.float()\n",
    "        \n",
    "            a,b,c,d=y.shape\n",
    "            y=y.reshape(a*b,c,d)\n",
    "        \n",
    "            x,y=x.to(device),y.to(device)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            loss_fn = DiceLoss().to(device)\n",
    "       \n",
    "            #eval\n",
    "            res = model(x)\n",
    "            res=res.to(device)\n",
    "            loss = loss_fn(res.permute(0,2,3,1).to(device),F.one_hot(y,num_classes=4).to(device)).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "            # Loss\n",
    "            print(\"Batch_id: \", index,\"Eval loss: \", loss.item())\n",
    "            epoch_loss+=loss.item()\n",
    "            \n",
    "            \n",
    "            # IoU\n",
    "\n",
    "            bac = iou(torch.argmax(res,dim = 1).to(device),y.to(device)).to(device)\n",
    "            print(\"Batch_id: \", index,\"Eval IoU: \", bac)\n",
    "            IoU.append(bac)\n",
    "            \n",
    "            # Dice Score\n",
    "            t,t0,t1,t2,t3=dic(res.permute(0,2,3,1).to(device),F.one_hot(y,num_classes=4).to(device))\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Eval Mean Dice Score: \", t)\n",
    "            md.append(t)\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Eval Non-tumor Dice Score: \", t0)\n",
    "            d0.append(t0)\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Eval NCR/NET Dice Score: \", t1)\n",
    "            d1.append(t1)\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Eval ED Dice Score: \", t2)\n",
    "            d2.append(t2)\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Eval ET Dice Score: \", t3)\n",
    "            d3.append(t3)\n",
    "            if index%10==0:\n",
    "                \n",
    "                img1=np.zeros((HEIGHT,WIDTH))\n",
    "                img1=torch.tensor(img1)\n",
    "                img1[:,:]=res.argmax(dim=1)[5,:,:]\n",
    "                img1[img1==3]=4\n",
    "                img2=np.zeros((HEIGHT,WIDTH))\n",
    "                img2=torch.tensor(img2)\n",
    "                img2[:,:]=y[5,:,:]\n",
    "                img2[img2==3]=4\n",
    "                figure()\n",
    "                imshow(img1)\n",
    "                show()\n",
    "                figure()\n",
    "                imshow(img2)\n",
    "                show()\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "    IoU=torch.tensor(IoU)\n",
    "    md = torch.tensor(md)\n",
    "    d0=torch.tensor(d0)\n",
    "    d1=torch.tensor(d1)\n",
    "    d2=torch.tensor(d2)\n",
    "    d3=torch.tensor(d3)\n",
    "    return torch.mean(IoU),epoch_loss,torch.mean(md),torch.mean(d0),torch.mean(d1),torch.mean(d2),torch.mean(d3)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8153203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Best Model\n",
    "def test(dataset):\n",
    "    print('test in session: ') \n",
    "    checkpoint = torch.load(MODEL_PATH+'#22-BEST')\n",
    "    model = Unet(in_channel=INPUT_CHANNEL,out_channel=4).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optim_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    Avg_dice = checkpoint['Eval Dice Scores']\n",
    "    non = checkpoint['Eval Non-tumor Dice Scores']\n",
    "    ncr = checkpoint['Eval NCR/NET Dice Scores']\n",
    "    ed = checkpoint['Eval ED Dice Scores']\n",
    "    et = checkpoint['Eval ET Dice Scores']\n",
    "    \n",
    "    print('Model loaded!','Epoch = ', epoch, 'Mean eval dice scores is: ',Avg_dice)\n",
    "    print('Dice Scorese Per class: ')\n",
    "    print('Non-Tumor: ', non)\n",
    "    print('NCR/NET: ', ncr)\n",
    "    print('ED: ', ed)\n",
    "    print('ET: ',et)\n",
    "    iou=torchmetrics.JaccardIndex('multiclass',num_classes=4,validate_args=False).to(device)\n",
    "    dic = DiceScore().to(device)\n",
    "    IoU=[]\n",
    "    md=[]\n",
    "    d0=[]\n",
    "    d1=[]\n",
    "    d2=[]\n",
    "    d3=[]\n",
    "    epoch_loss=0.0\n",
    "    dataset=tqdm(dataset)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for index, batch in enumerate(dataset):\n",
    "        \n",
    "            # reshape the data and load the data to gpu\n",
    "            x, y,other= batch \n",
    "            a,b,c,d,e=x.shape\n",
    "            x=x.reshape(a*b,c,d,e)\n",
    "            x=x.float()\n",
    "        \n",
    "            a,b,c,d=y.shape\n",
    "            y=y.reshape(a*b,c,d)\n",
    "        \n",
    "            x,y=x.to(device),y.to(device)\n",
    "       \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            loss_fn = DiceLoss().to(device)\n",
    "       \n",
    "            #test\n",
    "            res = model(x)\n",
    "            res=res.to(device)\n",
    "            loss = loss_fn(res.permute(0,2,3,1).to(device),F.one_hot(y,num_classes=4).to(device)).to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "            # Loss\n",
    "            print(\"Batch_id: \", index,\"Test loss: \", loss.item())\n",
    "            epoch_loss+=loss.item()\n",
    "            \n",
    "            \n",
    "            # IoU\n",
    "\n",
    "            bac = iou(torch.argmax(res,dim = 1).to(device),y.to(device)).to(device)\n",
    "            print(\"Batch_id: \", index,\"Test IoU: \", bac)\n",
    "            IoU.append(bac)\n",
    "            \n",
    "            \n",
    "            # Dice Score\n",
    "            t,t0,t1,t2,t3=dic(res.permute(0,2,3,1).to(device),F.one_hot(y,num_classes=4).to(device))\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Test Mean Dice Score: \", t)\n",
    "            md.append(t)\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Test Non-tumor Dice Score: \", t0)\n",
    "            d0.append(t0)\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Test NCR/NET Dice Score: \", t1)\n",
    "            d1.append(t1)\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Test ED Dice Score: \", t2)\n",
    "            d2.append(t2)\n",
    "            \n",
    "            print(\"Batch_id: \", index,\"Test ET Dice Score: \", t3)\n",
    "            d3.append(t3)\n",
    "\n",
    "            img1=np.zeros((HEIGHT,WIDTH))\n",
    "            img1=torch.tensor(img1)\n",
    "            img1[:,:]=res.argmax(dim=1)[0,:,:]\n",
    "            img1[img1==3]=4\n",
    "            img2=np.zeros((HEIGHT,WIDTH))\n",
    "            img2=torch.tensor(img2)\n",
    "            img2[:,:]=y[0,:,:]\n",
    "            img2[img2==3]=4\n",
    "            figure()\n",
    "            imshow(img1)\n",
    "            show()\n",
    "            figure()\n",
    "            imshow(img2)\n",
    "            show()\n",
    "            \n",
    "    IoU=torch.tensor(IoU)\n",
    "    md = torch.tensor(md)\n",
    "    d0=torch.tensor(d0)\n",
    "    d1=torch.tensor(d1)\n",
    "    d2=torch.tensor(d2)\n",
    "    d3=torch.tensor(d3)\n",
    "    print('Avg IoU: ',torch.mean(IoU))\n",
    "    print('Avg Loss: ',epoch_loss/(36))\n",
    "    print('Avg Dice Scores: ', torch.mean(md))\n",
    "    print('Non-Tumor Dice Scores: ',torch.mean(d0))\n",
    "    print('NCR/NET Dice Scores: ',torch.mean(d1))\n",
    "    print('ED Dice Scores: ',torch.mean(d2))\n",
    "    print('ET Dice Scores: ', torch.mean(d3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5df04220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "\n",
    "def main(BEST_EVAL):\n",
    "    if LOAD_CURRENT:\n",
    "        train_data = torch.load(MODEL_PATH+'trdata.pth')\n",
    "        eval_data = torch.load(MODEL_PATH+'edata.pth')\n",
    "        test_data = torch.load(MODEL_PATH+'tdata.pth')\n",
    "    else:\n",
    "        train_data,eval_data,test_data = GetBraTS19Dataset(CSV_FILE,IMAGE_PATH,['t1ce','flair'],batch_size=BATCH_SIZE)\n",
    "        torch.save(train_data, MODEL_PATH+'trdata.pth')\n",
    "        torch.save(eval_data, MODEL_PATH+'edata.pth')\n",
    "        torch.save(test_data,MODEL_PATH+'tdata.pth')\n",
    "    \n",
    "    print('Data Loaded!')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Unet(in_channel=INPUT_CHANNEL,out_channel=4).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    sc = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,patience=5,factor = 0.5,threshold=0.1,mode = 'max',verbose = True)\n",
    "    if LOAD_CURRENT:\n",
    "        checkpoint = torch.load(MODEL_PATH+'#22-current')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        opt.load_state_dict(checkpoint['optim_state_dict'])\n",
    "        sc.load_state_dict(checkpoint['sche'])\n",
    "        index =torch.load(MODEL_PATH+'index.pt')\n",
    "        loss_value=torch.load(MODEL_PATH+'tloss.pt')\n",
    "        accuracy=torch.load(MODEL_PATH+'tac.pt')\n",
    "        eval_loss=torch.load(MODEL_PATH+'eloss.pt')\n",
    "        eval_accuracy=torch.load(MODEL_PATH+'eacc.pt')\n",
    "        mean_dice=torch.load(MODEL_PATH+'md.pt')\n",
    "        d0=torch.load(MODEL_PATH+'d0.pt')\n",
    "        d1=torch.load(MODEL_PATH+'d1.pt')\n",
    "        d2=torch.load(MODEL_PATH+'d2.pt')\n",
    "        d3=torch.load(MODEL_PATH+'d3.pt')\n",
    "        e_mean_dice=torch.load(MODEL_PATH+'emd.pt')\n",
    "        ed0=torch.load(MODEL_PATH+'ed0.pt')\n",
    "        ed1=torch.load(MODEL_PATH+'ed1.pt')\n",
    "        ed2=torch.load(MODEL_PATH+'ed2.pt')\n",
    "        ed3=torch.load(MODEL_PATH+'ed3.pt')     \n",
    "        ep = torch.load(MODEL_PATH+'ep.pt')\n",
    "        \n",
    "    else:\n",
    "        index =[]\n",
    "        loss_value=[]\n",
    "        accuracy=[]\n",
    "        eval_loss=[]\n",
    "        eval_accuracy=[]\n",
    "        mean_dice=[]\n",
    "        d0=[]\n",
    "        d1=[]\n",
    "        d2=[]\n",
    "        d3=[]\n",
    "        e_mean_dice=[]\n",
    "        ed0=[]\n",
    "        ed1=[]\n",
    "        ed2=[]\n",
    "        ed3=[]\n",
    "        ep = 0 \n",
    "    \n",
    "    \n",
    "    for i in range (ep,EPOCH):\n",
    "        print(f'Epoch: {i}')\n",
    "        \n",
    "        acc, loss_val,md,di0,di1,di2,di3=training(train_data,model.train(),opt, device,BATCH_SIZE,LEARNING_RATE)\n",
    "        \n",
    "        eacc,eloss_val,emd,edi0,edi1,edi2,edi3=evaluation(eval_data,model.eval())\n",
    "        sc.step(eloss_val)\n",
    "        \n",
    "        loss_value.append(loss_val/len(train_data.sampler))\n",
    "        accuracy.append(acc)\n",
    "        mean_dice.append(md)\n",
    "        d0.append(di0)\n",
    "        d1.append(di1)\n",
    "        d2.append(di2)\n",
    "        d3.append(di3)\n",
    "        \n",
    "        eval_loss.append(eloss_val/len(eval_data.sampler))\n",
    "        eval_accuracy.append(eacc)\n",
    "        e_mean_dice.append(emd)\n",
    "        ed0.append(edi0)\n",
    "        ed1.append(edi1)\n",
    "        ed2.append(edi2)\n",
    "        ed3.append(edi3)\n",
    "        \n",
    "        index.append(i)\n",
    "        ep=ep+1\n",
    "        \n",
    "        torch.save(index,MODEL_PATH+'index.pt')\n",
    "        torch.save(loss_value,MODEL_PATH+'tloss.pt')\n",
    "        torch.save(accuracy,MODEL_PATH+'tac.pt')\n",
    "        torch.save(eval_loss,MODEL_PATH+'eloss.pt')\n",
    "        torch.save(eval_accuracy,MODEL_PATH+'eacc.pt')\n",
    "        torch.save(mean_dice,MODEL_PATH+'md.pt')\n",
    "        torch.save(d0,MODEL_PATH+'d0.pt')\n",
    "        torch.save(d1,MODEL_PATH+'d1.pt')\n",
    "        torch.save(d2,MODEL_PATH+'d2.pt')\n",
    "        torch.save(d3,MODEL_PATH+'d3.pt')\n",
    "        torch.save(e_mean_dice,MODEL_PATH+'emd.pt')\n",
    "        torch.save(ed0,MODEL_PATH+'ed0.pt')\n",
    "        torch.save(ed1,MODEL_PATH+'ed1.pt')\n",
    "        torch.save(ed2,MODEL_PATH+'ed2.pt')\n",
    "        torch.save(ed3,MODEL_PATH+'ed3.pt')     \n",
    "        torch.save(ep,MODEL_PATH+'ep.pt')\n",
    "        \n",
    "        \n",
    "        print('Epoch ',i,'Training loss: ',loss_val/len(train_data.sampler))\n",
    "        print('Epoch ',i,'Evaluation loss: ',eloss_val/len(eval_data.sampler))\n",
    "        \n",
    "        print('Epoch ',i,'Training accuracy : ',acc)\n",
    "        print('Epoch ',i,'Evaluation accuracy : ',eacc)\n",
    "        \n",
    "        print('Epoch ',i,'Training Mean Dice Score: ',md)\n",
    "        print('Epoch ',i,'Eval Mean Dice Score: ',emd)\n",
    "        \n",
    "        print('Epoch ',i,'Training Non-tumor Dice Score: ',di0)\n",
    "        print('Epoch ',i,'Eval Non-tumor Dice Score: ',edi0)\n",
    "       \n",
    "        print('Epoch ',i,'Training NCR/NET Dice Score: ',di1)\n",
    "        print('Epoch ',i,'Eval NCR/NET Dice Score: ',edi1)\n",
    "        \n",
    "        print('Epoch ',i,'Training ED Dice Score: ',di2)\n",
    "        print('Epoch ',i,'Eval ED Dice Score: ',edi2)\n",
    "        \n",
    "        print('Epoch ',i,'Training ET Dice Score: ',di3)\n",
    "        print('Epoch ',i,'Eval ET Dice Score: ',edi3)\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optim_state_dict': opt.state_dict(),\n",
    "            'epoch': i,\n",
    "            'sche':sc.state_dict(),\n",
    "            'Training loss_values': loss_val/len(train_data.sampler),\n",
    "            'Training accuracy':acc,\n",
    "            'Eval loss_values': eloss_val/len(eval_data.sampler),\n",
    "            'Eval IoU':eacc,\n",
    "            'Training Dice Scores':md,\n",
    "            'Eval Dice Scores': emd,\n",
    "            'Training Non-tumor Dice Scores':di0,\n",
    "            'Eval Non-tumor Dice Scores':edi0,   \n",
    "            'Training NCR/NET Dice Scores': di1,\n",
    "            'Eval NCR/NET Dice Scores': edi1,   \n",
    "            'Training ED Dice Scores': di2,\n",
    "            'Eval ED Dice Scores': edi2,    \n",
    "            'Training ET Dice Scores': di3,\n",
    "            'Eval ET Dice Scores': edi3,    \n",
    "            }, MODEL_PATH+'#23-current')\n",
    "        print('Epoch completed and model successfully saved')\n",
    "        if BEST_EVAL < eacc :\n",
    "            torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optim_state_dict': opt.state_dict(),\n",
    "            'epoch': i,\n",
    "            'sche':sc.state_dict(),\n",
    "            'Training loss_values': loss_val/len(train_data.sampler),\n",
    "            'Training accuracy':acc,\n",
    "            'Eval loss_values': eloss_val/len(eval_data.sampler),\n",
    "            'Eval IoU':eacc,\n",
    "            'Training Dice Scores':md,\n",
    "            'Eval Dice Scores': emd,\n",
    "            'Training Non-tumor Dice Scores':di0,\n",
    "            'Eval Non-tumor Dice Scores':edi0,   \n",
    "            'Training NCR/NET Dice Scores': di1,\n",
    "            'Eval NCR/NET Dice Scores': edi1,   \n",
    "            'Training ED Dice Scores': di2,\n",
    "            'Eval ED Dice Scores': edi2,    \n",
    "            'Training ET Dice Scores': di3,\n",
    "            'Eval ET Dice Scores': edi3,    \n",
    "            }, MODEL_PATH+'#22-BEST')\n",
    "            print(\"Best Model saved!\")\n",
    "            BEST_EVAL = eacc\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        if eacc > 0.80:\n",
    "            break\n",
    "        \n",
    "    plt.plot(index, loss_value, label =\"Training \")\n",
    "    plt.plot(index,eval_loss, label = \"Validation\")\n",
    "    plt.title(\"Training and Validation Loss Curve: (Sample_size={}, lr={})\".format(BATCH_SIZE*SLICE_NUM ,LEARNING_RATE))\n",
    "    plt.xlabel(\"Epoch:\")\n",
    "    plt.ylabel(\"Average Loss \")\n",
    "    plt.legend()\n",
    "    plt.savefig(MODEL_PATH+ 'Training and eval Loss plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.plot(index, accuracy,label =\"Training \")\n",
    "    plt.plot(index, eval_accuracy,label =\"Validation \")\n",
    "    plt.title(\"Training and Validation IoU Scores (batch_size={}, lr={})\".format(BATCH_SIZE*SLICE_NUM, LEARNING_RATE))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (Mean IoU Scores)\")\n",
    "    plt.legend()\n",
    "    plt.savefig(MODEL_PATH+ 'Training and eval Accuracy plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(index, mean_dice, label =\"Training \")\n",
    "    plt.plot(index,e_mean_dice, label = \"Validation\")\n",
    "    plt.title(\"Training and Validation Mean Dice Scores: (Sample_size={}, lr={})\".format(BATCH_SIZE*SLICE_NUM ,LEARNING_RATE))\n",
    "    plt.xlabel(\"Epoch:\")\n",
    "    plt.ylabel(\"Mean Dice Scores: \")\n",
    "    plt.legend()\n",
    "    plt.savefig(MODEL_PATH+ 'Training and eval avg dice plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(index, d0, label =\"Non-Tumor \")\n",
    "    plt.plot(index,d1, label = \"NCT/NET\")\n",
    "    plt.plot(index, d2, label =\"ED \")\n",
    "    plt.plot(index,d3, label = \"ET\")\n",
    "    plt.title(\"Training Dice Scores per class: (Sample_size={}, lr={})\".format(BATCH_SIZE*SLICE_NUM ,LEARNING_RATE))\n",
    "    plt.xlabel(\"Epoch:\")\n",
    "    plt.ylabel(\"Mean Dice Scores: \")\n",
    "    plt.legend()\n",
    "    plt.savefig(MODEL_PATH+ 'Training dice per class plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(index, ed0, label =\"Non-Tumor \")\n",
    "    plt.plot(index,ed1, label = \"NCT/NET\")\n",
    "    plt.plot(index, ed2, label =\"ED \")\n",
    "    plt.plot(index,ed3, label = \"ET\")\n",
    "    plt.title(\"Validation Dice Scores per class: (Sample_size={}, lr={})\".format(BATCH_SIZE*SLICE_NUM ,LEARNING_RATE))\n",
    "    plt.xlabel(\"Epoch:\")\n",
    "    plt.ylabel(\"Mean Dice Scores: \")\n",
    "    plt.legend()\n",
    "    plt.savefig(MODEL_PATH+ 'Eval dice per class plot.png')\n",
    "    plt.show()\n",
    "    test(test_data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "783a6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "691ba938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Unet:\n\tMissing key(s) in state_dict: \"en1.1.weight\", \"en1.1.bias\", \"en2.1.weight\", \"en2.1.bias\", \"en3.1.weight\", \"en3.1.bias\", \"en4.1.weight\", \"en4.1.bias\", \"bn.2.weight\", \"bn.2.bias\", \"final.4.weight\", \"final.4.bias\". \n\tUnexpected key(s) in state_dict: \"en1.2.weight\", \"en1.2.bias\", \"en2.2.weight\", \"en2.2.bias\", \"en3.2.weight\", \"en3.2.bias\", \"en4.2.weight\", \"en4.2.bias\", \"bn.1.weight\", \"bn.1.bias\", \"final.5.weight\", \"final.5.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19660\\1521213077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \"\"\"\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19660\\2861129863.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(BEST_EVAL)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mLOAD_CURRENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'#22-current'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optim_state_dict'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sche'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FYP\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1670\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[1;32m-> 1672\u001b[1;33m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[0;32m   1673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Unet:\n\tMissing key(s) in state_dict: \"en1.1.weight\", \"en1.1.bias\", \"en2.1.weight\", \"en2.1.bias\", \"en3.1.weight\", \"en3.1.bias\", \"en4.1.weight\", \"en4.1.bias\", \"bn.2.weight\", \"bn.2.bias\", \"final.4.weight\", \"final.4.bias\". \n\tUnexpected key(s) in state_dict: \"en1.2.weight\", \"en1.2.bias\", \"en2.2.weight\", \"en2.2.bias\", \"en3.2.weight\", \"en3.2.bias\", \"en4.2.weight\", \"en4.2.bias\", \"bn.1.weight\", \"bn.1.bias\", \"final.5.weight\", \"final.5.bias\". "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "yellow - label 4\n",
    "dark blue - label 1 \n",
    "green - label 2 \n",
    "\n",
    "purple - label 0\n",
    "\"\"\"\n",
    "\n",
    "main(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b20c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYP",
   "language": "python",
   "name": "fyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
